{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182aeaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# Define constants\n",
    "num_classes = 2\n",
    "image_size = 224\n",
    "input_shape = (image_size, image_size, 3)\n",
    "labels = ['Malignant', 'Benign']\n",
    "\n",
    "# Function to load data\n",
    "def get_data(data_dir):\n",
    "    images = []\n",
    "    labels_list = []\n",
    "    for label in labels:\n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img))[..., ::-1]  # Convert BGR to RGB format\n",
    "                resized_arr = cv2.resize(img_arr, (image_size, image_size))  # Resize images\n",
    "                images.append(resized_arr)\n",
    "                labels_list.append(class_num)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return np.array(images), np.array(labels_list)\n",
    "\n",
    "# Load train and test data\n",
    "train_images, y_train = get_data('.../train')\n",
    "test_images, y_test = get_data('.../test')\n",
    "\n",
    "# Normalize data and shuffle\n",
    "x_train = train_images / 255.0\n",
    "x_test = test_images / 255.0\n",
    "from sklearn.utils import shuffle\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "x_test, y_test = shuffle(x_test, y_test)\n",
    "\n",
    "# Define model hyperparameters\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 0.00001\n",
    "dropout = 0.4\n",
    "batch_size = 16\n",
    "num_epochs = 15\n",
    "image_size = 224  \n",
    "patch_size = 16\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [projection_dim * 2, projection_dim,]\n",
    "transformer_layers = 4\n",
    "mlp_head_units = [2048, 1024]\n",
    "num_classes = 2\n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout)(x)  \n",
    "    return x\n",
    "#  custom layer \"Patches\"\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size, **kwargs):\n",
    "        super(Patches, self).__init__(**kwargs)\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Patches, self).get_config()\n",
    "        config.update({\"patch_size\": self.patch_size})\n",
    "        return config\n",
    "\n",
    "# Define custom layer \"PatchEncoder\"\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim, **kwargs):\n",
    "        super(PatchEncoder, self).__init__(**kwargs)\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return layers.Dropout(0.3)(encoded)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PatchEncoder, self).get_config()\n",
    "        config.update({\"num_patches\": self.num_patches, \"projection_dim\": self.projection.units})\n",
    "        return config\n",
    "\n",
    "def create_cnn_layer(input_shape):\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(x)  # Add another convolutional layer\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu')(x)  # Add another convolutional layer\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    cnn_model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "    return cnn_model\n",
    "\n",
    "# Create the Vision Transformer (ViT) model with CNN\n",
    "def create_vit_classifier(cnn_model):\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    cnn_output = cnn_model(inputs)\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    for _ in range(transformer_layers):\n",
    "        x1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        attention_output = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        x2 = tf.keras.layers.Add()([attention_output, encoded_patches])\n",
    "        x3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        encoded_patches = tf.keras.layers.Add()([x3, x2])\n",
    "\n",
    "    representation = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = tf.keras.layers.Flatten()(representation)\n",
    "    representation = tf.keras.layers.Dropout(dropout)(representation)\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=dropout)\n",
    "\n",
    "    combined_features = tf.keras.layers.Concatenate()([cnn_output, features])\n",
    "    logits = tf.keras.layers.Dense(num_classes)(combined_features)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model\n",
    "\n",
    "\n",
    "#  the CNN layer\n",
    "cnn_model = create_cnn_layer(input_shape)\n",
    "\n",
    "#  the combined model\n",
    "vit_classifier = create_vit_classifier(cnn_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6581299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "folder_num = 'Folder_name'\n",
    "data = {\n",
    "        \"learning_rate\":learning_rate, \n",
    "        \"weight_decay\":weight_decay, \n",
    "        \"batch_size\":batch_size,\n",
    "        \"num_epochs\":num_epochs,\n",
    "        \"image_size\":image_size,\n",
    "        \"optimizer\":'Adam',\n",
    "        \"patch_size\":patch_size,\n",
    "       \"projection_dim\":projection_dim,\n",
    "       \"num_heads\":num_heads,\n",
    "       \"transformer_units\":transformer_units,\n",
    "    \"transformer_layers\":transformer_layers,\n",
    "    \"mlp_head_units\":mlp_head_units,\n",
    "    \"dropout\":dropout,\n",
    "       }\n",
    "\n",
    "dir_name = '.../' + str(folder_num)\n",
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)\n",
    "else:\n",
    "    shutil.rmtree(dir_name)           \n",
    "    os.makedirs(dir_name)\n",
    "\n",
    "\n",
    "f = open(dir_name+\"/info.txt\", \"w\")\n",
    "f.write(\"{\\n\")\n",
    "for k in data.keys():\n",
    "    f.write(\"'{}':'{}'\\n\".format(k, data[k]))\n",
    "f.write(\"}\")\n",
    "f.close()\n",
    "\n",
    "print(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328f974f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "optimizer = tfa.optimizers.AdamW(learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "vit_classifier.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")],\n",
    ")\n",
    "history = vit_classifier.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    "    validation_split=0.1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0ee4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model\n",
    "save_dir = '.../' + str(folder_num) + '/saved_model/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "vit_classifier.save(os.path.join(save_dir, 'my_model.h5'))\n",
    "# Load the saved model with custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf092db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "\n",
    "image_size = 224  # You can adjust this based on your model's input size\n",
    "\n",
    "\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(os.path.join('D:/Practice/Result/29__31_3_2024/BUSI_RoI/saved_model', 'my_model.h5'), custom_objects={\"Patches\": Patches, \"PatchEncoder\": PatchEncoder})\n",
    "\n",
    "class_labels = ['Malignant', 'Benign']\n",
    "\n",
    "# Function to make predictions on all images in a folder and calculate accuracy\n",
    "def predict_and_calculate_accuracy(folder_path):\n",
    "    try:\n",
    "        if not os.path.isdir(folder_path):\n",
    "            print(f\"The provided path is not a valid directory: {folder_path}\")\n",
    "            return\n",
    "\n",
    "     \n",
    "        class_folders = [os.path.join(folder_path, class_name) for class_name in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, class_name))]\n",
    "        num_classes = len(class_folders)\n",
    "\n",
    "        if num_classes == 0:\n",
    "            print(f\"No subdirectories (classes) found in the folder: {folder_path}\")\n",
    "            return\n",
    "\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        true_labels = []\n",
    "        predicted_labels = []\n",
    "\n",
    "        for class_folder in class_folders:\n",
    "            class_name = os.path.basename(class_folder)\n",
    "\n",
    "            # Get a list of image files in the class folder\n",
    "            image_files = [f for f in os.listdir(class_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))]\n",
    "\n",
    "            for image_file in image_files:\n",
    "                image_path = os.path.join(class_folder, image_file)\n",
    "\n",
    "                # Read the image and preprocess it\n",
    "                img = cv2.imread(image_path)\n",
    "                if img is None:\n",
    "                    print(f\"Could not read the image: {image_path}\")\n",
    "                    continue\n",
    "\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB format\n",
    "                resized_img = cv2.resize(img, (image_size, image_size))\n",
    "                normalized_img = resized_img / 255.0  # Normalize the image\n",
    "\n",
    "                # Make the prediction\n",
    "                prediction = loaded_model.predict(np.array([normalized_img]))\n",
    "\n",
    "                # Get the predicted class index\n",
    "                predicted_class_index = np.argmax(prediction)\n",
    "                predicted_label = class_labels[predicted_class_index]\n",
    "\n",
    "                true_labels.append(class_name)\n",
    "                predicted_labels.append(predicted_label)\n",
    "\n",
    "                # Check if the predicted class matches the image folder name\n",
    "                if class_name.lower() == predicted_label.lower():\n",
    "                    correct_predictions += 1\n",
    "\n",
    "                total_predictions += 1\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = (correct_predictions / total_predictions) * 100\n",
    "        print(f\"Total Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "        # Calculate confusion matrix and print classification report\n",
    "        unique_labels = sorted(list(set(true_labels).union(set(predicted_labels))))\n",
    "        cm = confusion_matrix(true_labels, predicted_labels, labels=unique_labels)\n",
    "        report = classification_report(true_labels, predicted_labels, target_names=unique_labels)\n",
    "\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "        print(\"Classification Report:\")\n",
    "        print(report)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "# Provide the path to the folder containing the images you want to predict\n",
    "folder_path = '...../test'\n",
    "predict_and_calculate_accuracy(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54673b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
